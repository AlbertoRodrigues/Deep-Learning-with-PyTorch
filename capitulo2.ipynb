{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2949]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0786, 0.0892, 0.7270, 0.1052]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0, 1, 0])\n",
    "print(one_hot_numpy)\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes=3)\n",
    "print(one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0024, -0.0678, -0.2169,  0.1607,  0.0504,  0.0379, -0.1461,  0.0081,\n",
      "         -0.2060, -0.0472, -0.0003,  0.0440,  0.1925,  0.2046,  0.1847,  0.1424],\n",
      "        [ 0.0705,  0.1877, -0.1419, -0.1736,  0.2498,  0.1226, -0.1962,  0.0929,\n",
      "         -0.0346, -0.0576, -0.1628, -0.1369,  0.2022,  0.1927,  0.1896,  0.1245],\n",
      "        [ 0.1999, -0.2423, -0.0089, -0.0248, -0.2284,  0.2360,  0.0323, -0.0594,\n",
      "         -0.1892,  0.0297,  0.1970,  0.0228, -0.2337, -0.1264, -0.1885,  0.1599],\n",
      "        [-0.1014,  0.1895,  0.1721,  0.0664,  0.0844,  0.1454,  0.2420,  0.2079,\n",
      "         -0.1024,  0.1719,  0.1515,  0.0819,  0.0881,  0.1276, -0.1353,  0.1658],\n",
      "        [-0.1354,  0.1907, -0.1282,  0.0928, -0.1099, -0.1215, -0.0996,  0.0679,\n",
      "          0.0306,  0.1137,  0.1295, -0.1917,  0.2322, -0.2122,  0.1796, -0.1119],\n",
      "        [-0.1235, -0.0521,  0.1569, -0.0661, -0.0786, -0.0601,  0.1716,  0.0991,\n",
      "          0.1655, -0.2162,  0.1334, -0.1766,  0.1167, -0.1453,  0.2139,  0.0275],\n",
      "        [-0.0536, -0.1285, -0.0369, -0.0943,  0.0076,  0.1006, -0.0326,  0.2413,\n",
      "          0.0202, -0.0036, -0.1114,  0.1470, -0.0608,  0.2418,  0.1277,  0.0256],\n",
      "        [-0.1989, -0.0587, -0.0246, -0.0132,  0.1244, -0.1082, -0.0774,  0.2172,\n",
      "          0.2244,  0.1843, -0.1224,  0.0762, -0.0498,  0.0020,  0.1929, -0.0112]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1945, -0.0607], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2)\n",
    "                     )\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "print(weight_0)\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[1].bias\n",
    "print(bias_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(1, 16)\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                        nn.Linear(8, 4), \n",
    "                        nn.Linear(4, 2),\n",
    "                        nn.Softmax(dim=1))\n",
    "prediction = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss() \n",
    "loss = criterion(prediction, target) \n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0358, -0.0371, -0.0369, -0.0166,  0.0039, -0.0603, -0.0160, -0.0459,\n",
      "          0.0452, -0.0155,  0.0487,  0.0454,  0.0495, -0.0401,  0.0424,  0.0493],\n",
      "        [ 0.0385,  0.0399,  0.0397,  0.0179, -0.0042,  0.0650,  0.0172,  0.0494,\n",
      "         -0.0486,  0.0167, -0.0525, -0.0489, -0.0533,  0.0432, -0.0457, -0.0531],\n",
      "        [-0.0045, -0.0047, -0.0047, -0.0021,  0.0005, -0.0077, -0.0020, -0.0058,\n",
      "          0.0057, -0.0020,  0.0062,  0.0058,  0.0063, -0.0051,  0.0054,  0.0063],\n",
      "        [-0.0441, -0.0457, -0.0455, -0.0205,  0.0048, -0.0744, -0.0197, -0.0566,\n",
      "          0.0557, -0.0192,  0.0601,  0.0560,  0.0611, -0.0495,  0.0523,  0.0608],\n",
      "        [-0.0179, -0.0185, -0.0184, -0.0083,  0.0020, -0.0302, -0.0080, -0.0230,\n",
      "          0.0226, -0.0078,  0.0244,  0.0227,  0.0248, -0.0201,  0.0212,  0.0246],\n",
      "        [ 0.0409,  0.0424,  0.0421,  0.0190, -0.0045,  0.0690,  0.0182,  0.0525,\n",
      "         -0.0516,  0.0178, -0.0557, -0.0519, -0.0566,  0.0458, -0.0485, -0.0563],\n",
      "        [ 0.0065,  0.0067,  0.0067,  0.0030, -0.0007,  0.0109,  0.0029,  0.0083,\n",
      "         -0.0082,  0.0028, -0.0088, -0.0082, -0.0090,  0.0073, -0.0077, -0.0089],\n",
      "        [ 0.0651,  0.0674,  0.0671,  0.0302, -0.0071,  0.1098,  0.0290,  0.0835,\n",
      "         -0.0822,  0.0283, -0.0887, -0.0826, -0.0901,  0.0730, -0.0772, -0.0896]])\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "weight0 = model[0].weight\n",
    "weight1 = model[1].weight\n",
    "weight2 = model[2].weight\n",
    "\n",
    "# Access the gradients of the weight of each linear layer\n",
    "grads0 = weight0.grad\n",
    "grads1 = weight1.grad\n",
    "grads2 = weight2.grad\n",
    "print(grads0)\n",
    "\n",
    "# Update the weights using the learning rate and the gradients\n",
    "weight0 = weight0 - lr*grads0\n",
    "weight1 = weight1 - lr*grads1\n",
    "weight2 = weight2 - lr*grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loss = criterion(prediction, target)\n",
    "loss.backward()\n",
    "\n",
    "# Update the model's parameters using the optimizer\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(10)\n",
    "y = np.array(4)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = (y - y_pred)**2\n",
    "\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_pred, dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n",
    "print(mse_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gen_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
