{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosseno (Bag of Words): 0.5\n",
      "Jaccard: 0.6\n"
     ]
    }
   ],
   "source": [
    "def cosine_bow_similarity(frase1, frase2):\n",
    "    vetorizar = CountVectorizer().fit_transform([frase1, frase2])\n",
    "    matriz = vetorizar.toarray()\n",
    "    similaridade = cosine_similarity(matriz)\n",
    "    return similaridade[0, 1]\n",
    "\n",
    "def jaccard_similarity(frase1, frase2):\n",
    "    set1 = set(frase1.lower().split())\n",
    "    set2 = set(frase2.lower().split())\n",
    "    intersecao = set1.intersection(set2)\n",
    "    uniao = set1.union(set2)\n",
    "    return len(intersecao) / len(uniao) if uniao else 0.0\n",
    "\n",
    "# Exemplos\n",
    "f1 = \"A casa é azul\"\n",
    "f2 = \"A casa é verde\"\n",
    "\n",
    "print(\"Cosseno (Bag of Words):\", round(cosine_bow_similarity(f1, f2), 3))\n",
    "print(\"Jaccard:\", round(jaccard_similarity(f1, f2), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21573691  0.18270384 -0.01125517  0.03685256 -0.01532448 -0.00880565\n",
      "  0.3670183   0.17374927 -0.0828202  -0.2361189 ]\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo de embedding\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Duas palavras similares\n",
    "palavra1 = \"carro\"\n",
    "palavra2 = \"gato\"\n",
    "\n",
    "# Gerar embeddings\n",
    "embedding1 = model.encode(palavra1)\n",
    "#embedding2 = model.encode(palavra2)\n",
    "\n",
    "# Calcular similaridade do cosseno\n",
    "#similaridade = cosine_similarity(\n",
    "#    [embedding1],\n",
    "#    [embedding2]\n",
    "#)[0][0]\n",
    "\n",
    "#print(f\"Similaridade entre '{palavra1}' e '{palavra2}': {similaridade:.4f}\")\n",
    "print(embedding1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\anaconda3\\envs\\env_gen_ai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# Carregando um modelo leve e eficaz\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02514462  0.02419465 -0.0337151   0.00544109 -0.05224889 -0.05682078\n",
      "  0.09118187  0.04109337 -0.03356854  0.01619318]\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "# Palavra de exemplo\n",
    "palavra = \"inteligência\"\n",
    "\n",
    "# Gerando o embedding\n",
    "embedding1 = model.encode(palavra)\n",
    "\n",
    "# Mostrando as primeiras 10 dimensões\n",
    "print(embedding[:10])\n",
    "print(embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image       # pdfplumber usa PIL internamente\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_conteudo_pdf(caminho_pdf):\n",
    "    \"\"\"Extrai texto, imagens (via OCR) e tabelas de um PDF em uma única string.\"\"\"\n",
    "    conteudo = []  # lista de segmentos de texto extraídos\n",
    "\n",
    "    with pdfplumber.open(caminho_pdf) as pdf:\n",
    "        for num_pagina, pagina in enumerate(pdf.pages, start=1):\n",
    "            # Extrai texto da página (se houver)\n",
    "            texto = pagina.extract_text()\n",
    "            if texto:\n",
    "                conteudo.append(texto)\n",
    "            \n",
    "            # Extrai tabelas da página (se alguma)\n",
    "            tabelas = pagina.extract_tables()\n",
    "            for tabela in tabelas:\n",
    "                if tabela:\n",
    "                    # Converte lista de linhas em DataFrame pandas para formatação\n",
    "                    # A primeira linha da tabela pode ser cabeçalho (usada aqui como nomes de coluna)\n",
    "                    df = pd.DataFrame(tabela[1:], columns=tabela[0] if tabela[0] else None)\n",
    "                    # Converte a tabela em string (formato tabular) e adiciona\n",
    "                    conteudo.append(df.to_string(index=False))\n",
    "            \n",
    "            # Extrai imagens da página e aplica OCR\n",
    "            for img_meta in pagina.images:\n",
    "                # Obtém coordenadas da imagem no PDF\n",
    "                x0 = img_meta[\"x0\"]\n",
    "                top = img_meta[\"top\"]\n",
    "                x1 = img_meta[\"x1\"]\n",
    "                bottom = img_meta[\"bottom\"]\n",
    "                # Recorta a região da imagem na página\n",
    "                recorte = pagina.crop((x0, top, x1, bottom))\n",
    "                # Converte o recorte em uma imagem PIL (aumentar resolução para melhorar OCR se necessário)\n",
    "                pil_img = recorte.to_image(resolution=150).original\n",
    "                # Aplica OCR na imagem recortada\n",
    "                texto_img = pytesseract.image_to_string(pil_img, lang=\"por\")  # lang=\"por\" para OCR em português, se aplicável\n",
    "                texto_img = texto_img.strip()\n",
    "                if texto_img:\n",
    "                    # Opcional: indicar no texto que era conteúdo de imagem ou posição original\n",
    "                    conteudo.append(f\"[Imagem na página {num_pagina}]\\n{texto_img}\")\n",
    "    \n",
    "    # Junta todos os pedaços em uma única string, separando por quebras de linha entre partes\n",
    "    return \"\\n\\n\".join(conteudo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = extrair_conteudo_pdf(\"pdf_teste.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de PDF para Teste\n",
      "Este PDF contém texto, tabela e imagem.\n",
      "Ana | 25 | São Paulo\n",
      "Bruno | 30 | Rio de Janeiro\n",
      "Carla | 22 | Belo Horizonte\n",
      "\n",
      "[Imagem na página 1]\n",
      "1.0\n",
      "\n",
      "0.5\n",
      "\n",
      "0.0\n",
      "\n",
      "—O0.5\n",
      "\n",
      "—1.0\n",
      "\n",
      "Gráfico Seno\n",
      "\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gen_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
